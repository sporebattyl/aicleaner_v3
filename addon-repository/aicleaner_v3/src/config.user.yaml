# ------------------------------------------------------------------------------
# User Configuration Overrides for AICleaner v3
#
# This file demonstrates how to override default settings.
# Only include settings you want to change from defaults.
# See config.default.yaml for all available options and defaults.
#
# OVERRIDE BEHAVIOR:
# - Dictionary values: Your settings merge with defaults (you only specify what changes)
# - List values: Your lists completely replace defaults (specify the entire list)
# - Environment variables: Use ${VAR_NAME} syntax for secrets and dynamic values
#
# VALIDATION: The application validates your configuration on startup.
# Invalid configurations will prevent startup with detailed error messages.
#
# For complete documentation, see README.md Configuration section.
# ------------------------------------------------------------------------------

# Example: Switch to OpenAI as primary provider
general:
  active_provider: openai
  log_level: DEBUG  # More verbose for power users

# Example: Provider-specific configurations
ai_providers:
  openai:
    api_key: ${OPENAI_API_KEY}
    default_model: gpt-4o
    models:
      gpt-4o:
        temperature: 0.5  # Override default temperature
        max_tokens: 2048  # Custom token limit
  
  # Example: Gemini with model-specific overrides
  gemini:
    api_key: ${GEMINI_API_KEY}
    default_model: gemini-2.5-flash  # Use flash for faster responses
    models:
      gemini-2.5-pro:
        generation_config:
          temperature: 0.6  # Lower temperature for more focused responses
      gemini-2.5-flash:
        generation_config:
          temperature: 0.5
          max_output_tokens: 4096
      gemini-2.5-flash-lite:
        generation_config:
          temperature: 0.4  # Very focused for simple tasks
          max_output_tokens: 2048

  # Example: Local Ollama setup with custom server
  ollama:
    base_url: http://192.168.1.100:11434  # Custom server IP
    default_model: mistral
    models:
      mistral:
        options:
          temperature: 0.6
          
  # Example: Anthropic with custom settings
  anthropic:
    api_key: ${ANTHROPIC_API_KEY}
    models:
      claude-3-5-sonnet-20241022:
        temperature: 0.4
        max_tokens: 8192

# Example: Production MQTT setup
mqtt:
  broker:
    host: mqtt.homelab.local
    port: 8883
    user: ${MQTT_USER}
    password: ${MQTT_PASSWORD}
  
  # Override auto-discovery settings
  auto_discovery:
    enabled: true
    topic_prefix: ha_custom  # Custom discovery prefix
  
  # Example: Explicit device configurations (override auto-discovery)
  # IMPORTANT: This list will REPLACE the default devices list completely
  devices:
    - name: "Living Room Vacuum"
      unique_id: "vacuum_roborock_01" 
      state_topic: "vacuum/roborock/state"
      command_topic: "vacuum/roborock/cmd"
      ai_override:
        provider: anthropic
        model: claude-3-5-sonnet-20241022
    
    - name: "Kitchen Lights"
      unique_id: "lights_kitchen_main"
      state_topic: "zigbee2mqtt/kitchen_lights"
      command_topic: "zigbee2mqtt/kitchen_lights/set"
      ai_override:
        provider: gemini
        model: gemini-2.5-pro

# Example: Performance tuning for power users
performance:
  metrics_enabled: true  # Ensure metrics are enabled
  metrics_file: /custom/path/metrics.json  # Custom metrics location
  metrics_flush_interval: 30  # More frequent flushing
  metrics_retention_days: 90  # Keep metrics longer
  metrics_rollup_enabled: true  # Enable efficient rollups
  cache:
    enabled: true
    ttl: 7200  # 2 hours instead of default 1 hour

# Example: Custom service configuration  
service:
  api:
    host: 0.0.0.0
    port: 9000  # Custom port instead of default 8000
    api_key: ${AICLEANER_API_KEY}
  
  home_assistant:
    url: https://ha.example.com  # External HA instance
    token: ${HA_TOKEN}

# Example: Feature toggles - Disable defaults or enable experimental features
feature_flags:
  # Disable auto-discovery if you prefer explicit configuration
  mqtt_auto_discovery: true  # Keep enabled (this is just an example)
  
  # Enable experimental features
  experimental_caching: true
  advanced_metrics: true
  
  # Disable features that might interfere with custom setups
  automatic_model_switching: false  # Power users often want manual control